{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cb70cd-5f53-4098-abed-c12a27a15994",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Dict, Any\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# --- Directories ---\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\"))\n",
    "RESULTS_DIR = os.path.join(PROJECT_ROOT, \"results\")\n",
    "EXPERIMENTS_DIR = os.path.join(PROJECT_ROOT, \"experiments\")\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "os.makedirs(EXPERIMENTS_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "def train_one_epoch(model: nn.Module, dataloader: DataLoader, optimizer, device: str, epoch: int):\n",
    "    model.train()\n",
    "    prog = tqdm(dataloader, desc=f\"Epoch {epoch}\")\n",
    "    running_loss = 0.0\n",
    "    for batch in prog:\n",
    "        images, bboxes, classes = batch\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)  # placeholder forward\n",
    "        if isinstance(outputs, dict) and \"loss\" in outputs:\n",
    "            loss = outputs[\"loss\"]\n",
    "        else:\n",
    "            loss = torch.tensor(0.0, requires_grad=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += float(loss.item())\n",
    "        prog.set_postfix({\"loss\": running_loss / (prog.n + 1)})\n",
    "    return running_loss / max(1, len(dataloader))\n",
    "\n",
    "\n",
    "def run_training(model: nn.Module, train_loader: DataLoader,\n",
    "                 val_loader: Optional[DataLoader] = None,\n",
    "                 device: str = \"cuda\", epochs: int = 20, lr: float = 1e-3,\n",
    "                 experiment_name: str = \"exp_detection\") -> Dict[str, Any]:\n",
    "\n",
    "    model.to(device)\n",
    "    opt = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "    history = {\"train_loss\": []}\n",
    "\n",
    "    for e in range(1, epochs + 1):\n",
    "        avg_loss = train_one_epoch(model, train_loader, opt, device, e)\n",
    "        history[\"train_loss\"].append(avg_loss)\n",
    "\n",
    "    # --- Save plots ---\n",
    "    plt.figure()\n",
    "    plt.plot(range(1, epochs + 1), history[\"train_loss\"], marker=\"o\", label=\"Train Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Detection Training Loss\")\n",
    "    plt.legend()\n",
    "    plot_path = os.path.join(RESULTS_DIR, f\"{experiment_name}_loss.png\")\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close()\n",
    "\n",
    "    # --- Save experiment log ---\n",
    "    exp_record = {\n",
    "        \"experiment\": experiment_name,\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"params\": {\"epochs\": epochs, \"lr\": lr, \"device\": device},\n",
    "        \"history\": history\n",
    "    }\n",
    "    log_path = os.path.join(EXPERIMENTS_DIR, f\"{experiment_name}_log.json\")\n",
    "    with open(log_path, \"w\") as f:\n",
    "        json.dump(exp_record, f, indent=2)\n",
    "\n",
    "    print(f\"✅ Results plot saved to {plot_path}\")\n",
    "    print(f\"✅ Experiment log saved to {log_path}\")\n",
    "    return exp_record\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"This module is a training skeleton. We need to integrate our own models.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
